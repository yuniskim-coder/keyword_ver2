"""
ë³¸ í”„ë¡œê·¸ë¨ 'RankChecker by L&C'ëŠ” chaechaeLabì— ì˜í•´ ê°œë°œëœ ì†Œí”„íŠ¸ì›¨ì–´ì…ë‹ˆë‹¤.
í•´ë‹¹ ì†ŒìŠ¤ì½”ë“œ ë° ì‹¤í–‰ íŒŒì¼ì˜ ë¬´ë‹¨ ë³µì œ, ë°°í¬, ì—­ì»´íŒŒì¼, ìˆ˜ì •ì€
ì €ì‘ê¶Œë²• ë° ì»´í“¨í„°í”„ë¡œê·¸ë¨ ë³´í˜¸ë²•ì— ë”°ë¼ ì—„ê²©íˆ ê¸ˆì§€ë©ë‹ˆë‹¤.

ë¬´ë‹¨ ìœ í¬ ë° ìƒì—…ì  ì´ìš© ì‹œ ë¯¼í˜•ì‚¬ìƒ ë²•ì  ì±…ì„ì„ ë¬¼ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
â€» ë³¸ í”„ë¡œê·¸ë¨ì€ ì‚¬ìš©ì ì¶”ì  ë° ì°¨ë‹¨ ê¸°ëŠ¥ì´ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤.

Copyright â“’ 2025 chaechaeLab. All rights reserved.
Unauthorized reproduction or redistribution is strictly prohibited. 
"""

import streamlit as st
import json
import urllib.request
import urllib.parse
import re
from datetime import datetime, timedelta
import time
import pandas as pd
import hashlib

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” - ê°•ì œ ë¦¬ì…‹
if 'logged_in' not in st.session_state:
    st.session_state.logged_in = False
if 'username' not in st.session_state:
    st.session_state.username = None

# ì„¸ì…˜ ê°•ì œ ì´ˆê¸°í™” (ê°œë°œìš©)
if 'force_reset' not in st.session_state:
    st.session_state.force_reset = True
    st.session_state.logged_in = False
    st.session_state.username = None

# ë¡œê·¸ì¸ ìê²© ì¦ëª… (ì‹¤ì œ ìš´ì˜í™˜ê²½ì—ì„œëŠ” ë°ì´í„°ë² ì´ìŠ¤ë‚˜ ì™¸ë¶€ ì¸ì¦ ì‹œìŠ¤í…œ ì‚¬ìš© ê¶Œì¥)
VALID_CREDENTIALS = {
    "master": "56tyghbn"
}

# ë„¤ì´ë²„ ì´ˆë¡ìƒ‰ ìŠ¤íƒ€ì¼ CSS ì¶”ê°€
st.markdown("""
<style>
/* ë„¤ì´ë²„ ì´ˆë¡ìƒ‰ ë²„íŠ¼ ìŠ¤íƒ€ì¼ */
.stButton > button {
    background-color: #03C75A !important;
    color: white !important;
    border: none !important;
    border-radius: 6px !important;
    font-weight: 600 !important;
    padding: 0.5rem 1rem !important;
    font-size: 16px !important;
    transition: all 0.3s ease !important;
}

.stButton > button:hover {
    background-color: #02B051 !important;
    box-shadow: 0 2px 8px rgba(3, 199, 90, 0.3) !important;
    transform: translateY(-1px) !important;
}

.stButton > button:active {
    background-color: #029E47 !important;
    transform: translateY(0px) !important;
}

/* ì£¼ìš” ê²€ìƒ‰ ë²„íŠ¼ì— íŠ¹ë³„í•œ ìŠ¤íƒ€ì¼ ì ìš© */
div[data-testid="stButton"] button[kind="primary"] {
    background: linear-gradient(135deg, #03C75A 0%, #02B051 100%) !important;
    box-shadow: 0 4px 15px rgba(3, 199, 90, 0.25) !important;
    font-size: 17px !important;
    font-weight: 700 !important;
    padding: 0.75rem 1.5rem !important;
}

div[data-testid="stButton"] button[kind="primary"]:hover {
    background: linear-gradient(135deg, #02B051 0%, #029E47 100%) !important;
    box-shadow: 0 6px 20px rgba(3, 199, 90, 0.4) !important;
}

/* ìŠ¤í”¼ë„ˆ ìƒ‰ìƒë„ ë„¤ì´ë²„ ì´ˆë¡ìƒ‰ìœ¼ë¡œ */
.stSpinner > div {
    border-top-color: #03C75A !important;
}

/* ë¡œê·¸ì¸ í˜ì´ì§€ ìŠ¤íƒ€ì¼ */
.login-container {
    max-width: 400px;
    margin: 0 auto;
    padding: 2rem;
    background: white;
    border-radius: 12px;
    box-shadow: 0 4px 20px rgba(0, 0, 0, 0.1);
    border: 1px solid #e0e0e0;
}

.login-header {
    text-align: center;
    margin-bottom: 2rem;
    color: #333;
}

.login-welcome {
    background: linear-gradient(135deg, #03C75A, #02B051);
    color: white;
    padding: 1rem;
    border-radius: 8px;
    text-align: center;
    margin-bottom: 1rem;
}
</style>
""", unsafe_allow_html=True)

# ë„¤ì´ë²„ API í‚¤ ì„¤ì •
client_id = "tp2ypJeFL98lJyTSWLy5"
client_secret = "QeYFNiR0k7"

def login_page():
    """ë¡œê·¸ì¸ í˜ì´ì§€"""
    st.markdown('<div class="login-container">', unsafe_allow_html=True)
    
    st.markdown('<div class="login-header">', unsafe_allow_html=True)
    st.markdown("# ğŸ” chaechaeLab")
    st.markdown("### ë§ˆì¼€íŒ… ë„êµ¬ ë¡œê·¸ì¸")
    st.markdown('</div>', unsafe_allow_html=True)
    
    # ë¡œê·¸ì¸ í¼
    with st.form("login_form"):
        username = st.text_input("ì‚¬ìš©ì ID", placeholder="ì•„ì´ë””ë¥¼ ì…ë ¥í•˜ì„¸ìš”")
        password = st.text_input("ë¹„ë°€ë²ˆí˜¸", type="password", placeholder="ë¹„ë°€ë²ˆí˜¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”")
        submit_button = st.form_submit_button("ë¡œê·¸ì¸", width="stretch")
        
        if submit_button:
            if authenticate_user(username, password):
                st.session_state.logged_in = True
                st.session_state.username = username
                st.success("ë¡œê·¸ì¸ ì„±ê³µ!")
                st.rerun()
            else:
                st.error("ì•„ì´ë”” ë˜ëŠ” ë¹„ë°€ë²ˆí˜¸ê°€ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤.")
    
    st.markdown('</div>', unsafe_allow_html=True)
    
    # ë„ì›€ë§ ì •ë³´
    st.markdown("---")
    st.markdown("**ğŸ“± chaechaeLab ë§ˆì¼€íŒ… ë„êµ¬**")
    st.markdown("- ë„¤ì´ë²„ ì‡¼í•‘ ìˆœìœ„ ì²´í¬")
    st.markdown("- ì—°ê´€ í‚¤ì›Œë“œ ë¶„ì„")
    st.markdown("- ì‡¼í•‘ ë­í‚¹ ì¡°íšŒ")
    st.markdown("- ì›”ê°„ ê²€ìƒ‰ëŸ‰ ë¶„ì„")

def authenticate_user(username, password):
    """ì‚¬ìš©ì ì¸ì¦"""
    return username in VALID_CREDENTIALS and VALID_CREDENTIALS[username] == password

def logout():
    """ë¡œê·¸ì•„ì›ƒ"""
    st.session_state.logged_in = False
    st.session_state.username = None
    st.rerun()

def show_user_info():
    """ì‚¬ìš©ì ì •ë³´ í‘œì‹œ ë° ë¡œê·¸ì•„ì›ƒ ë²„íŠ¼"""
    col1, col2 = st.columns([3, 1])
    
    with col1:
        st.markdown(f'<div class="login-welcome">ğŸ‘‹ í™˜ì˜í•©ë‹ˆë‹¤, {st.session_state.username}ë‹˜!</div>', 
                   unsafe_allow_html=True)
    
    with col2:
        if st.button("ë¡œê·¸ì•„ì›ƒ", key="logout_btn"):
            logout()

def get_keyword_competition_level(keyword):
    """í‚¤ì›Œë“œì˜ PCí†µí•©ê²€ìƒ‰ì˜ì—­ ê¸°ì¤€ ê²½ìŸì •ë„ë¥¼ ë¶„ì„í•˜ëŠ” í•¨ìˆ˜"""
    try:
        # ë„¤ì´ë²„ í†µí•©ê²€ìƒ‰ APIë¥¼ ì‚¬ìš©í•˜ì—¬ ê²€ìƒ‰ ê²°ê³¼ ìˆ˜ í™•ì¸
        encText = urllib.parse.quote(keyword)
        url = f"https://openapi.naver.com/v1/search/webkr.json?query={encText}&display=1&start=1"
        
        request = urllib.request.Request(url)
        request.add_header("X-Naver-Client-Id", client_id)
        request.add_header("X-Naver-Client-Secret", client_secret)
        response = urllib.request.urlopen(request)
        result = json.loads(response.read())
        
        total_results = result.get("total", 0)
        
        # ê²½ìŸì •ë„ íŒì • ê¸°ì¤€
        if total_results >= 1000000:  # 100ë§Œ ê°œ ì´ìƒ
            return "ë†’ìŒ", total_results, "ğŸ”´"
        elif total_results >= 100000:  # 10ë§Œ ê°œ ì´ìƒ
            return "ì¤‘ê°„", total_results, "ğŸŸ¡"
        else:  # 10ë§Œ ê°œ ë¯¸ë§Œ
            return "ë‚®ìŒ", total_results, "ğŸŸ¢"
            
    except Exception as e:
        return "ì•Œ ìˆ˜ ì—†ìŒ", 0, "âšª"

def get_related_keywords(keyword):
    """ë„¤ì´ë²„ DataLab ê¸°ë°˜ ì‹¤ì œ ê²€ìƒ‰ íŠ¸ë Œë“œ ì—°ê´€í‚¤ì›Œë“œ ì¡°íšŒ"""
    try:
        return get_datalab_trend_keywords(keyword)
    except Exception as e:
        st.error(f"ì—°ê´€ í‚¤ì›Œë“œ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return []

def get_datalab_trend_keywords(keyword):
    """DataLab API ê¸°ë°˜ ì‹¤ì œ ê²€ìƒ‰ íŠ¸ë Œë“œ í‚¤ì›Œë“œ"""
    try:
        # 1. ê¸°ë³¸ í‚¤ì›Œë“œ íŒ¨í„´ ìƒì„±
        candidate_keywords = generate_keyword_candidates(keyword)
        
        # 2. DataLab APIë¡œ ì‹¤ì œ ê²€ìƒ‰ëŸ‰ ê²€ì¦
        verified_keywords = verify_keywords_with_datalab(candidate_keywords, keyword)
        
        # 3. ì‡¼í•‘ íŠ¸ë Œë“œ ê¸°ë°˜ ì¶”ê°€ í‚¤ì›Œë“œ
        shopping_keywords = get_shopping_trend_keywords(keyword)
        verified_keywords.extend(shopping_keywords)
        
        # 4. ì¤‘ë³µ ì œê±° ë° ìµœì¢… ì •ë ¬
        final_keywords = finalize_keyword_list(verified_keywords, keyword)
        
        return final_keywords[:20]
        
    except Exception as e:
        st.error(f"DataLab API ì˜¤ë¥˜: {str(e)}")
        return get_emergency_keywords(keyword)

def generate_keyword_candidates(keyword):
    """ê´‘ê³ ì£¼ì„¼í„° ìŠ¤íƒ€ì¼ì˜ í‚¤ì›Œë“œ í›„ë³´ ìƒì„±"""
    candidates = []
    
    # 1. êµ¬ë§¤ ì˜ë„ í‚¤ì›Œë“œ (ê´‘ê³  íš¨ê³¼ê°€ ë†’ì€ í‚¤ì›Œë“œë“¤)
    purchase_intents = [
        f"{keyword} ì¶”ì²œ", f"{keyword} ìˆœìœ„", f"{keyword} ë² ìŠ¤íŠ¸",
        f"{keyword} ê°€ê²©", f"{keyword} í• ì¸", f"{keyword} íŠ¹ê°€",
        f"{keyword} ë¦¬ë·°", f"{keyword} í›„ê¸°", f"{keyword} êµ¬ë§¤",
        f"ì¢‹ì€ {keyword}", f"ì¸ê¸° {keyword}", f"ìµœê³  {keyword}"
    ]
    candidates.extend(purchase_intents)
    
    # 2. ë¸Œëœë“œ/í’ˆì§ˆ í‚¤ì›Œë“œ
    quality_keywords = [
        f"í”„ë¦¬ë¯¸ì—„ {keyword}", f"ê³ ê¸‰ {keyword}", f"ë¸Œëœë“œ {keyword}",
        f"ì •í’ˆ {keyword}", f"ì‹ ìƒ {keyword}", f"ìµœì‹  {keyword}",
        f"ê°€ì„±ë¹„ {keyword}", f"ì €ë ´í•œ {keyword}"
    ]
    candidates.extend(quality_keywords)
    
    # 3. ê¸°ëŠ¥/íŠ¹ì„± í‚¤ì›Œë“œ
    feature_keywords = [
        f"ë¬´ì„  {keyword}", f"ë¸”ë£¨íˆ¬ìŠ¤ {keyword}", f"USB {keyword}",
        f"íœ´ëŒ€ìš© {keyword}", f"ì†Œí˜• {keyword}", f"ëŒ€ìš©ëŸ‰ {keyword}",
        f"ê²Œì´ë° {keyword}", f"ì‚¬ë¬´ìš© {keyword}", f"ê°€ì •ìš© {keyword}"
    ]
    candidates.extend(feature_keywords)
    
    # 4. ì‡¼í•‘/êµ¬ë§¤ì²˜ í‚¤ì›Œë“œ
    shopping_keywords = [
        f"{keyword} ì¿ íŒ¡", f"{keyword} 11ë²ˆê°€", f"{keyword} ì§€ë§ˆì¼“",
        f"{keyword} ì˜¨ë¼ì¸", f"{keyword} ì‡¼í•‘ëª°", f"{keyword} ë§¤ì¥",
        f"{keyword} ë¬´ë£Œë°°ì†¡", f"{keyword} ë‹¹ì¼ë°°ì†¡"
    ]
    candidates.extend(shopping_keywords)
    
    return candidates

def verify_keywords_with_datalab(candidates, base_keyword):
    """DataLab APIë¡œ í‚¤ì›Œë“œ ê²€ì¦"""
    verified = []
    
    # ë°°ì¹˜ ì²˜ë¦¬ (API ì œí•œ ê³ ë ¤)
    batch_size = 5
    for i in range(0, len(candidates), batch_size):
        batch = candidates[i:i+batch_size]
        
        try:
            # DataLab API ìš”ì²­
            volumes = get_batch_search_volume(batch)
            
            for j, kw in enumerate(batch):
                if j < len(volumes) and volumes[j] > 0:
                    verified.append((kw, volumes[j]))
                    
        except Exception as e:
            # API ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ì ìˆ˜ë¡œ ì¶”ê°€
            for kw in batch:
                verified.append((kw, 1))
    
    # ê²€ìƒ‰ëŸ‰ ìˆœ ì •ë ¬
    verified.sort(key=lambda x: x[1], reverse=True)
    
    return [kw for kw, vol in verified[:15]]

def get_batch_search_volume(keywords):
    """í‚¤ì›Œë“œ ë°°ì¹˜ì˜ ê²€ìƒ‰ëŸ‰ ì¡°íšŒ (DataLab API)"""
    try:
        url = "https://openapi.naver.com/v1/datalab/search"
        
        # í‚¤ì›Œë“œ ê·¸ë£¹ êµ¬ì„±
        keyword_groups = []
        for i, kw in enumerate(keywords[:5]):  # ìµœëŒ€ 5ê°œ
            keyword_groups.append({
                "groupName": f"group{i+1}",
                "keywords": [kw]
            })
        
        body = {
            "startDate": "2024-01-01",
            "endDate": "2024-10-31",
            "timeUnit": "month",
            "keywordGroups": keyword_groups,
            "device": "",
            "ages": [],
            "gender": ""
        }
        
        request = urllib.request.Request(url)
        request.add_header("X-Naver-Client-Id", client_id)
        request.add_header("X-Naver-Client-Secret", client_secret)
        request.add_header("Content-Type", "application/json")
        
        response = urllib.request.urlopen(request, json.dumps(body).encode("utf-8"), timeout=10)
        result = json.loads(response.read().decode("utf-8"))
        
        # ê²€ìƒ‰ëŸ‰ ì¶”ì¶œ
        volumes = []
        if "results" in result:
            for group_result in result["results"]:
                if "data" in group_result and len(group_result["data"]) > 0:
                    # ìµœê·¼ 3ê°œì›” í‰ê·  ê³„ì‚°
                    recent_data = group_result["data"][-3:]
                    avg_volume = sum(point["ratio"] for point in recent_data) / len(recent_data)
                    volumes.append(avg_volume)
                else:
                    volumes.append(0)
        
        # ë¶€ì¡±í•œ ë¶€ë¶„ì€ 0ìœ¼ë¡œ ì±„ìš°ê¸°
        while len(volumes) < len(keywords):
            volumes.append(0)
            
        return volumes
        
    except Exception as e:
        # API ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ê°’ ë°˜í™˜
        return [1] * len(keywords)

def get_shopping_trend_keywords(keyword):
    """ì‡¼í•‘ íŠ¸ë Œë“œ ê¸°ë°˜ í‚¤ì›Œë“œ (ì‹¤ì œ ìƒí’ˆ ë°ì´í„° í™œìš©)"""
    try:
        # ë„¤ì´ë²„ ì‡¼í•‘ APIë¡œ ìµœì‹  ìƒí’ˆ ê²€ìƒ‰
        encText = urllib.parse.quote(keyword)
        url = f"https://openapi.naver.com/v1/search/shop.json?query={encText}&display=100&start=1&sort=date"
        
        request = urllib.request.Request(url)
        request.add_header("X-Naver-Client-Id", client_id)
        request.add_header("X-Naver-Client-Secret", client_secret)
        
        response = urllib.request.urlopen(request, timeout=10)
        result = json.loads(response.read())
        
        # ìƒí’ˆëª…ì—ì„œ íŠ¸ë Œë“œ í‚¤ì›Œë“œ ì¶”ì¶œ
        trend_keywords = extract_trending_keywords(result.get("items", []), keyword)
        
        return trend_keywords
        
    except Exception:
        return []

def extract_trending_keywords(products, base_keyword):
    """ìƒí’ˆ ë°ì´í„°ì—ì„œ íŠ¸ë Œë”© í‚¤ì›Œë“œ ì¶”ì¶œ"""
    keyword_freq = {}
    
    for product in products:
        title = re.sub(r'<[^>]+>', '', product.get('title', ''))
        
        # 2-4ê¸€ì í•œê¸€ í‚¤ì›Œë“œ ì¶”ì¶œ
        korean_words = re.findall(r'[ê°€-í£]{2,4}', title)
        for word in korean_words:
            if (word != base_keyword and 
                word not in ['ë°°ì†¡', 'ë¬´ë£Œ', 'ë‹¹ì¼', 'íƒë°°', 'í¬ì¥', 'ê°œë´‰'] and
                len(word) >= 2):
                keyword_freq[word] = keyword_freq.get(word, 0) + 1
        
        # ì˜ë¬¸ ë¸Œëœë“œëª… ì¶”ì¶œ
        english_words = re.findall(r'[A-Z][a-zA-Z]{2,8}', title)
        for word in english_words:
            if word.lower() != base_keyword.lower():
                keyword_freq[word] = keyword_freq.get(word, 0) + 1
    
    # ë¹ˆë„ ë†’ì€ í‚¤ì›Œë“œë¡œ ì¡°í•© ìƒì„±
    trending = []
    for word, freq in sorted(keyword_freq.items(), key=lambda x: x[1], reverse=True):
        if freq >= 3:  # 3ë²ˆ ì´ìƒ ë“±ì¥
            trending.append(f"{word} {base_keyword}")
            trending.append(f"{base_keyword} {word}")
            if len(trending) >= 10:
                break
    
    return trending

def finalize_keyword_list(keywords, base_keyword):
    """ìµœì¢… í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸ ì •ë¦¬"""
    # ì¤‘ë³µ ì œê±°
    unique_keywords = []
    seen = set()
    
    for kw in keywords:
        kw_clean = kw.strip().lower()
        if (kw_clean != base_keyword.lower() and 
            kw_clean not in seen and 
            len(kw.strip()) >= 2):
            unique_keywords.append(kw.strip())
            seen.add(kw_clean)
    
    # í’ˆì§ˆ ì ìˆ˜ ê³„ì‚° ë° ì •ë ¬
    scored_keywords = []
    for kw in unique_keywords:
        score = calculate_ad_relevance_score(kw, base_keyword)
        scored_keywords.append((kw, score))
    
    # ì ìˆ˜ìˆœ ì •ë ¬
    scored_keywords.sort(key=lambda x: x[1], reverse=True)
    
    return [kw for kw, score in scored_keywords]

def calculate_ad_relevance_score(keyword, base_keyword):
    """ê´‘ê³  ê´€ë ¨ì„± ì ìˆ˜ ê³„ì‚°"""
    score = 10  # ê¸°ë³¸ ì ìˆ˜
    
    # êµ¬ë§¤ ì˜ë„ í‚¤ì›Œë“œ ê°€ì‚°ì 
    high_intent = ['ì¶”ì²œ', 'ìˆœìœ„', 'ê°€ê²©', 'í• ì¸', 'íŠ¹ê°€', 'êµ¬ë§¤', 'ë² ìŠ¤íŠ¸', 'ì¸ê¸°']
    intent_score = sum(3 for intent in high_intent if intent in keyword)
    score += intent_score
    
    # ë¸Œëœë“œ/í’ˆì§ˆ í‚¤ì›Œë“œ ê°€ì‚°ì 
    quality_terms = ['í”„ë¦¬ë¯¸ì—„', 'ê³ ê¸‰', 'ë¸Œëœë“œ', 'ì •í’ˆ', 'ìµœê³ ', 'ì‹ ìƒ']
    quality_score = sum(2 for term in quality_terms if term in keyword)
    score += quality_score
    
    # ê¸°ìˆ /ê¸°ëŠ¥ í‚¤ì›Œë“œ ê°€ì‚°ì 
    tech_terms = ['ë¬´ì„ ', 'ë¸”ë£¨íˆ¬ìŠ¤', 'USB', 'ê²Œì´ë°', 'ì¶©ì „', 'LED']
    tech_score = sum(2 for term in tech_terms if term in keyword)
    score += tech_score
    
    # ì‡¼í•‘ ê´€ë ¨ í‚¤ì›Œë“œ ê°€ì‚°ì 
    shopping_terms = ['ì¿ íŒ¡', 'ì§€ë§ˆì¼“', '11ë²ˆê°€', 'ì˜¨ë¼ì¸', 'ì‡¼í•‘', 'ë°°ì†¡']
    shopping_score = sum(1 for term in shopping_terms if term in keyword)
    score += shopping_score
    
    # ê¸¸ì´ ì ìˆ˜
    if 4 <= len(keyword) <= 15:
        score += 3
    elif 16 <= len(keyword) <= 25:
        score += 1
    
    # ë¶ˆìš©ì–´ ê°ì 
    stop_words = ['ê²ƒ', 'ê±°', 'ì´ê²ƒ', 'ê·¸ê²ƒ', 'ë¬¼ê±´', 'ìƒí’ˆ']
    penalty = sum(5 for stop in stop_words if stop in keyword)
    score -= penalty
    
    return max(0, score)

def get_emergency_keywords(keyword):
    """ë¹„ìƒìš© í‚¤ì›Œë“œ (ëª¨ë“  API ì‹¤íŒ¨ ì‹œ)"""
    emergency = [
        f"{keyword} ì¶”ì²œ", f"{keyword} ìˆœìœ„", f"{keyword} ê°€ê²©", f"{keyword} í• ì¸",
        f"{keyword} ë¦¬ë·°", f"{keyword} í›„ê¸°", f"{keyword} êµ¬ë§¤", f"{keyword} ë² ìŠ¤íŠ¸",
        f"ì¢‹ì€ {keyword}", f"ì¸ê¸° {keyword}", f"ìµœê³  {keyword}", f"í”„ë¦¬ë¯¸ì—„ {keyword}",
        f"ê°€ì„±ë¹„ {keyword}", f"ì €ë ´í•œ {keyword}", f"ë¬´ì„  {keyword}", f"ë¸Œëœë“œ {keyword}",
        f"{keyword} ì˜¨ë¼ì¸", f"{keyword} ì‡¼í•‘", f"{keyword} íŠ¹ê°€", f"{keyword} ì‚¬ìš©ë²•"
    ]
    return emergency

def analyze_keyword_types(keywords, base_keyword):
    """í‚¤ì›Œë“œ ìœ í˜•ë³„ ë¶„ë¥˜ ë° ë¶„ì„"""
    analysis = {
        'êµ¬ë§¤ì˜ë„': 0,
        'ë¸Œëœë“œ/í’ˆì§ˆ': 0,
        'ê¸°ëŠ¥/íŠ¹ì„±': 0,
        'ê°€ê²©/í• ì¸': 0,
        'ê¸°íƒ€': 0
    }
    
    for keyword in keywords:
        # êµ¬ë§¤ ì˜ë„ í‚¤ì›Œë“œ
        if any(intent in keyword for intent in ['ì¶”ì²œ', 'ìˆœìœ„', 'êµ¬ë§¤', 'ë¦¬ë·°', 'í›„ê¸°', 'ë¹„êµ']):
            analysis['êµ¬ë§¤ì˜ë„'] += 1
        # ë¸Œëœë“œ/í’ˆì§ˆ í‚¤ì›Œë“œ
        elif any(brand in keyword for brand in ['ë¸Œëœë“œ', 'ì •í’ˆ', 'í”„ë¦¬ë¯¸ì—„', 'ê³ ê¸‰', 'ë² ìŠ¤íŠ¸', 'ì¸ê¸°']):
            analysis['ë¸Œëœë“œ/í’ˆì§ˆ'] += 1
        # ê¸°ëŠ¥/íŠ¹ì„± í‚¤ì›Œë“œ
        elif any(feature in keyword for feature in ['ë¬´ì„ ', 'ë¸”ë£¨íˆ¬ìŠ¤', 'USB', 'ê²Œì´ë°', 'ì‚¬ë¬´ìš©', 'ê°€ì •ìš©']):
            analysis['ê¸°ëŠ¥/íŠ¹ì„±'] += 1
        # ê°€ê²©/í• ì¸ í‚¤ì›Œë“œ
        elif any(price in keyword for price in ['ê°€ê²©', 'í• ì¸', 'íŠ¹ê°€', 'ì„¸ì¼', 'ì €ë ´', 'ê°€ì„±ë¹„']):
            analysis['ê°€ê²©/í• ì¸'] += 1
        else:
            analysis['ê¸°íƒ€'] += 1
    
    # 0ì¸ í•­ëª© ì œê±°
    return {k: v for k, v in analysis.items() if v > 0}

def get_keyword_insights(keywords, base_keyword):
    """í‚¤ì›Œë“œ ì¸ì‚¬ì´íŠ¸ ë¶„ì„"""
    insights = {}
    
    # ê¸¸ì´ í†µê³„
    lengths = [len(kw) for kw in keywords]
    insights['avg_length'] = sum(lengths) / len(lengths)
    insights['min_length'] = min(lengths)
    insights['max_length'] = max(lengths)
    
    # êµ¬ë§¤ ì˜ë„ í‚¤ì›Œë“œ ë¹„ìœ¨
    purchase_keywords = [kw for kw in keywords if any(intent in kw for intent in ['ì¶”ì²œ', 'ê°€ê²©', 'í• ì¸', 'êµ¬ë§¤', 'ìˆœìœ„'])]
    insights['purchase_ratio'] = len(purchase_keywords) / len(keywords) * 100
    
    # ê³ ìœ  ë‹¨ì–´ ìˆ˜
    all_words = set()
    for kw in keywords:
        all_words.update(kw.split())
    insights['unique_words'] = len(all_words)
    
    return insights

# ì´ì „ í¬ë¡¤ë§ í•¨ìˆ˜ë“¤ì´ ë„¤ì´ë²„ ê´‘ê³ ì£¼ì„¼í„° í‚¤ì›Œë“œ ë„êµ¬ ì‹œìŠ¤í…œìœ¼ë¡œ êµì²´ë¨

# ì´ì „ DataLab í•¨ìˆ˜ë“¤ì´ ì‹¤ì œ ì—°ê´€ê²€ìƒ‰ì–´ í¬ë¡¤ë§ ì‹œìŠ¤í…œìœ¼ë¡œ êµì²´ë¨

# ì´ì „ í•¨ìˆ˜ë“¤ì´ ìƒˆë¡œìš´ DataLab ê¸°ë°˜ ì‹œìŠ¤í…œìœ¼ë¡œ êµì²´ë¨

# ê¸°ì¡´ í•¨ìˆ˜ë“¤ ì œê±°í•˜ê³  ìƒˆë¡œìš´ êµ¬í˜„ìœ¼ë¡œ ëŒ€ì²´ë¨

def get_shopping_rank_list(keyword, limit=50):
    """ì‡¼í•‘ ìˆœìœ„ ë¦¬ìŠ¤íŠ¸ë¥¼ ì¡°íšŒí•˜ëŠ” í•¨ìˆ˜"""
    try:
        encText = urllib.parse.quote(keyword)
        url = f"https://openapi.naver.com/v1/search/shop.json?query={encText}&display={limit}&start=1"
        request = urllib.request.Request(url)
        request.add_header("X-Naver-Client-Id", client_id)
        request.add_header("X-Naver-Client-Secret", client_secret)
        response = urllib.request.urlopen(request)
        result = json.loads(response.read())
        
        products = []
        for idx, item in enumerate(result.get("items", []), start=1):
            title_clean = re.sub(r"<.*?>", "", item["title"])
            products.append({
                "rank": idx,
                "title": title_clean,
                "price": int(item["lprice"]) if item["lprice"] else 0,
                "link": item["link"],
                "mallName": item.get("mallName", "ì•Œ ìˆ˜ ì—†ìŒ"),
                "category1": item.get("category1", ""),
                "category2": item.get("category2", "")
            })
        
        return products
    except Exception as e:
        st.error(f"ì‡¼í•‘ ìˆœìœ„ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return []

def get_keyword_search_volume(keyword):
    """í‚¤ì›Œë“œì˜ ì›”ê°„ ê²€ìƒ‰ìˆ˜ë¥¼ ì¡°íšŒí•˜ëŠ” í•¨ìˆ˜ (ë„¤ì´ë²„ DataLab API)"""
    try:
        # ë„¤ì´ë²„ DataLab API ìš”ì²­ URL
        url = "https://openapi.naver.com/v1/datalab/search"
        
        # API ìš”ì²­ í—¤ë”
        headers = {
            "X-Naver-Client-Id": client_id,
            "X-Naver-Client-Secret": client_secret,
            "Content-Type": "application/json"
        }
        
        # ê²€ìƒ‰ ê¸°ê°„ ì„¤ì • (ìµœê·¼ 1ë…„)
        from datetime import datetime, timedelta
        end_date = datetime.now()
        start_date = end_date - timedelta(days=365)
        
        # API ìš”ì²­ ë°”ë””
        body = {
            "startDate": start_date.strftime("%Y-%m-%d"),
            "endDate": end_date.strftime("%Y-%m-%d"),
            "timeUnit": "month",
            "keywordGroups": [
                {
                    "groupName": keyword,
                    "keywords": [keyword]
                }
            ],
            "device": "",  # ì „ì²´ (PC + ëª¨ë°”ì¼)
            "ages": [],    # ì „ì²´ ì—°ë ¹
            "gender": ""   # ì „ì²´ ì„±ë³„
        }
        
        # PC ê²€ìƒ‰ëŸ‰ ì¡°íšŒ
        body_pc = body.copy()
        body_pc["device"] = "pc"
        
        request_pc = urllib.request.Request(url, data=json.dumps(body_pc).encode('utf-8'), headers=headers)
        response_pc = urllib.request.urlopen(request_pc)
        result_pc = json.loads(response_pc.read())
        
        # ëª¨ë°”ì¼ ê²€ìƒ‰ëŸ‰ ì¡°íšŒ
        body_mobile = body.copy()
        body_mobile["device"] = "mo"
        
        request_mobile = urllib.request.Request(url, data=json.dumps(body_mobile).encode('utf-8'), headers=headers)
        response_mobile = urllib.request.urlopen(request_mobile)
        result_mobile = json.loads(response_mobile.read())
        
        # ë°ì´í„° ì²˜ë¦¬
        if result_pc.get("results") and result_mobile.get("results"):
            pc_data = result_pc["results"][0]["data"]
            mobile_data = result_mobile["results"][0]["data"]
            
            # ìµœê·¼ ì›” ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
            latest_pc = pc_data[-1]["ratio"] if pc_data else 0
            latest_mobile = mobile_data[-1]["ratio"] if mobile_data else 0
            
            # ìƒëŒ€ì  ê²€ìƒ‰ëŸ‰ì„ ì‹¤ì œ ìˆ˜ì¹˜ë¡œ ë³€í™˜ (ì¶”ì •ì¹˜)
            # DataLab APIëŠ” ìƒëŒ€ì  ìˆ˜ì¹˜ë¥¼ ì œê³µí•˜ë¯€ë¡œ, ì‹¤ì œ ê²€ìƒ‰ëŸ‰ìœ¼ë¡œ ë³€í™˜
            base_multiplier = 1000  # ê¸°ë³¸ ìŠ¹ìˆ˜
            pc_volume = int(latest_pc * base_multiplier)
            mobile_volume = int(latest_mobile * base_multiplier)
            total_volume = pc_volume + mobile_volume
            
            if total_volume > 0:
                pc_ratio = (pc_volume / total_volume) * 100
                mobile_ratio = (mobile_volume / total_volume) * 100
            else:
                pc_ratio = mobile_ratio = 0
            
            return {
                "keyword": keyword,
                "total_volume": total_volume,
                "pc_volume": pc_volume,
                "mobile_volume": mobile_volume,
                "pc_ratio": pc_ratio,
                "mobile_ratio": mobile_ratio,
                "pc_trend_data": pc_data,
                "mobile_trend_data": mobile_data
            }
        else:
            st.warning(f"{keyword}: ê²€ìƒ‰ëŸ‰ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return None
            
    except urllib.error.HTTPError as e:
        if e.code == 400:
            st.error(f"API ìš”ì²­ ì˜¤ë¥˜: ì˜ëª»ëœ ìš”ì²­ì…ë‹ˆë‹¤. í‚¤ì›Œë“œë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
        elif e.code == 401:
            st.error(f"API ì¸ì¦ ì˜¤ë¥˜: API í‚¤ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
        elif e.code == 403:
            st.error(f"API ê¶Œí•œ ì˜¤ë¥˜: DataLab API ì‚¬ìš© ê¶Œí•œì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
        elif e.code == 429:
            st.error(f"API í˜¸ì¶œ ì œí•œ: ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
        else:
            st.error(f"HTTP ì˜¤ë¥˜ {e.code}: {e.reason}")
        return None
    except Exception as e:
        st.error(f"ê²€ìƒ‰ëŸ‰ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return None

def get_top_ranked_product_by_mall(keyword, mall_name, progress_placeholder=None):
    """íŠ¹ì • í‚¤ì›Œë“œì—ì„œ íŠ¹ì • ì‡¼í•‘ëª°ì˜ ìµœê³  ìˆœìœ„ ìƒí’ˆì„ ì°¾ëŠ” í•¨ìˆ˜"""
    encText = urllib.parse.quote(keyword)
    seen_titles = set()
    best_product = None
    
    # ê²€ìƒ‰ ê²°ê³¼ë¥¼ 1000ìœ„ê¹Œì§€ í™•ì¸ (100ê°œì”© 10ë²ˆ)
    for start in range(1, 1001, 100):
        try:
            url = f"https://openapi.naver.com/v1/search/shop.json?query={encText}&display=100&start={start}"
            request = urllib.request.Request(url)
            request.add_header("X-Naver-Client-Id", client_id)
            request.add_header("X-Naver-Client-Secret", client_secret)
            response = urllib.request.urlopen(request)
            result = json.loads(response.read())
            
            # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
            if progress_placeholder:
                progress_percent = min(start / 1000, 1.0)
                progress_placeholder.progress(progress_percent)
            
            for idx, item in enumerate(result.get("items", []), start=1):
                if item.get("mallName") and mall_name in item["mallName"]:
                    title_clean = re.sub(r"<.*?>", "", item["title"])
                    if title_clean in seen_titles:
                        continue
                    seen_titles.add(title_clean)
                    
                    rank = start + idx - 1
                    product = {
                        "rank": rank,
                        "title": title_clean,
                        "price": item["lprice"],
                        "link": item["link"],
                        "mallName": item["mallName"]
                    }
                    
                    if not best_product or rank < best_product["rank"]:
                        best_product = product
                        
        except Exception as e:
            st.error(f"ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            break
    
    return best_product

def main():
    # í˜ì´ì§€ ì„¤ì •
    st.set_page_config(
        page_title="chaechaeLab ë§ˆì¼€íŒ… ë„êµ¬",
        page_icon="ğŸ”",
        layout="wide"
    )
    
    # ì„¸ì…˜ ìƒíƒœ ê°•ì œ í™•ì¸ ë° ì´ˆê¸°í™”
    if 'logged_in' not in st.session_state:
        st.session_state.logged_in = False
    if 'username' not in st.session_state:
        st.session_state.username = None
    
    # ë””ë²„ê·¸: í˜„ì¬ ë¡œê·¸ì¸ ìƒíƒœ í™•ì¸
    # st.write(f"Debug: logged_in = {st.session_state.logged_in}")  # í…ŒìŠ¤íŠ¸ìš©
    
    # ë¡œê·¸ì¸ í™•ì¸ - ë¡œê·¸ì¸ë˜ì§€ ì•Šì•˜ìœ¼ë©´ ë¡œê·¸ì¸ í˜ì´ì§€ í‘œì‹œ
    if not st.session_state.logged_in:
        login_page()
        return
    
    # ë¡œê·¸ì¸ëœ ì‚¬ìš©ì ì •ë³´ í‘œì‹œ
    show_user_info()
    
    # íƒ€ì´í‹€
    st.title("ğŸ” chaechaeLab ë§ˆì¼€íŒ… ë„êµ¬")
    st.write("ë„¤ì´ë²„ ê¸°ë°˜ ì¢…í•© ë§ˆì¼€íŒ… ë¶„ì„ ë„êµ¬ì…ë‹ˆë‹¤.")
    
    # ì‚¬ì´ë“œë°”ì— ì‚¬ìš©ë²• ì•ˆë‚´
    with st.sidebar:
        st.header("ğŸ“– ì‚¬ìš©ë²• ì•ˆë‚´")
        st.markdown("""
        ### ğŸ” chaechaeLab ë§ˆì¼€íŒ… ë„êµ¬
        
        **ğŸ¯ ìˆœìœ„ í™•ì¸ê¸°**
        - ë„¤ì´ë²„ ì‡¼í•‘ì—ì„œ íŠ¹ì • íŒë§¤ì²˜ì˜ ìƒí’ˆ ìˆœìœ„ í™•ì¸
        - ìµœëŒ€ 10ê°œ í‚¤ì›Œë“œ ë™ì‹œ ê²€ìƒ‰
        - 1000ìœ„ê¹Œì§€ ì •í™•í•œ ìˆœìœ„ ë¶„ì„
        
        **ğŸ”— ì—°ê´€ í‚¤ì›Œë“œ**
        - ì…ë ¥í•œ í‚¤ì›Œë“œì™€ ê´€ë ¨ëœ ê²€ìƒ‰ì–´ ì¶”ì²œ
        - ë„¤ì´ë²„ DataLab ê¸°ë°˜ íŠ¸ë Œë“œ ë¶„ì„
        - ë§ˆì¼€íŒ… ì „ëµ ìˆ˜ë¦½ì— í™œìš©
        
        **ğŸ›ï¸ ì‡¼í•‘ ë­í‚¹**
        - ë„¤ì´ë²„ ì‡¼í•‘ ì¸ê¸° ìƒí’ˆ ìˆœìœ„
        - ì¹´í…Œê³ ë¦¬ë³„ TOP ìƒí’ˆ ë¶„ì„
        - ì‹œì¥ íŠ¸ë Œë“œ íŒŒì•…
        
        **ğŸ“ˆ ì›”ê°„ ê²€ìƒ‰ëŸ‰**
        - í‚¤ì›Œë“œë³„ ì›”ê°„ ê²€ìƒ‰ íŠ¸ë Œë“œ
        - ì‹œê¸°ë³„ ê²€ìƒ‰ëŸ‰ ë³€í™” ë¶„ì„
        - ë°ì´í„° ê¸°ë°˜ ë§ˆì¼€íŒ… ê³„íš ìˆ˜ë¦½
        """)
    
    # ë©”ì¸ ì˜ì—­ì— ì…ë ¥ í¼
    st.header("ğŸ” ê²€ìƒ‰ ì„¤ì •")
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        # ê²€ìƒ‰ì–´ ì…ë ¥
        keywords_text = st.text_area(
            "ê²€ìƒ‰ì–´ (ìµœëŒ€ 10ê°œ, ì‰¼í‘œë¡œ êµ¬ë¶„)", 
            placeholder="ì˜ˆ: í‚¤ë³´ë“œ, ë§ˆìš°ìŠ¤, ì¶©ì „ê¸°",
            height=100
        )
    
    with col2:
        # íŒë§¤ì²˜ëª… ì…ë ¥ (ê¸°ë³¸ ìˆœìœ„ í™•ì¸ìš©)
        mall_name = st.text_input(
            "íŒë§¤ì²˜ëª… (ìˆœìœ„ í™•ì¸ìš©)", 
            placeholder="ì˜ˆ: OOìŠ¤í† ì–´"
        )
    
    # íƒ­ ìƒì„±
    tab1, tab2, tab3, tab4 = st.tabs(["ğŸ¯ ìˆœìœ„ í™•ì¸", "ğŸ”— ì—°ê´€í‚¤ì›Œë“œ ì¡°íšŒ", "ğŸ“Š ì‡¼í•‘ ìˆœìœ„ ë¦¬ìŠ¤íŠ¸", "ğŸ“ˆ ì›”ê°„ ê²€ìƒ‰ìˆ˜"])
    
    with tab1:
        # ê¸°ì¡´ ìˆœìœ„ í™•ì¸ ê¸°ëŠ¥
        search_button = st.button("ğŸ” ìˆœìœ„ í™•ì¸", type="primary", key="rank_check")
        
        if search_button:
            # ì…ë ¥ê°’ ê²€ì¦
            keywords = [k.strip() for k in keywords_text.split(",") if k.strip()]
            
            if not keywords:
                st.error("âŒ ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                return
                
            if not mall_name.strip():
                st.error("âŒ íŒë§¤ì²˜ëª…ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                return
                
            if len(keywords) > 10:
                st.error("âŒ ê²€ìƒ‰ì–´ëŠ” ìµœëŒ€ 10ê°œê¹Œì§€ ê°€ëŠ¥í•©ë‹ˆë‹¤.")
                return
            
            # ê²€ìƒ‰ ì‹¤í–‰
            st.header("ğŸ“Š ê²€ìƒ‰ ê²°ê³¼")
            
            # ì „ì²´ ì§„í–‰ë¥ 
            overall_progress = st.progress(0)
            status_text = st.empty()
            
            results = []
            total_keywords = len(keywords)
            
            for i, keyword in enumerate(keywords):
                # í˜„ì¬ í‚¤ì›Œë“œ í‘œì‹œ
                status_text.text(f"ğŸ”„ ê²€ìƒ‰ ì¤‘: {keyword} ({i+1}/{total_keywords})")
                
                # ê°œë³„ í‚¤ì›Œë“œ ì§„í–‰ë¥ 
                keyword_progress = st.progress(0)
                
                # ê²€ìƒ‰ ì‹¤í–‰
                result = get_top_ranked_product_by_mall(keyword, mall_name, keyword_progress)
                
                # ê²°ê³¼ ì €ì¥
                results.append({
                    'keyword': keyword,
                    'result': result
                })
                
                # ì „ì²´ ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
                overall_progress.progress((i + 1) / total_keywords)
                
                # ê°œë³„ ì§„í–‰ë¥  ì™„ë£Œ
                keyword_progress.progress(1.0)
                
                # ì ì‹œ ëŒ€ê¸° (API í˜¸ì¶œ ì œí•œ ê³ ë ¤)
                time.sleep(0.5)
            
            # ê²€ìƒ‰ ì™„ë£Œ
            status_text.text("âœ… ê²€ìƒ‰ ì™„ë£Œ!")
            
            # ê²°ê³¼ í‘œì‹œ
            st.subheader("ğŸ¯ ê²€ìƒ‰ ê²°ê³¼ ìƒì„¸")
            
            for result_data in results:
                keyword = result_data['keyword']
                result = result_data['result']
                
                with st.expander(f"ğŸ” {keyword}", expanded=True):
                    if result:
                        col1, col2 = st.columns([2, 1])
                        
                        with col1:
                            st.markdown(f"**âœ… ê²€ìƒ‰ ì„±ê³µ**")
                            st.markdown(f"**ìˆœìœ„:** {result['rank']}ìœ„")
                            st.markdown(f"**ìƒí’ˆëª…:** {result['title']}")
                            st.markdown(f"**ê°€ê²©:** {int(result['price']):,}ì›")
                            st.markdown(f"**íŒë§¤ì²˜:** {result['mallName']}")
                            
                        with col2:
                            st.markdown(f"**ìƒí’ˆ ë§í¬:**")
                            st.markdown(f"[ğŸ”— ìƒí’ˆ ë³´ê¸°]({result['link']})")
                            
                            # ìˆœìœ„ì— ë”°ë¥¸ ìƒ‰ìƒ í‘œì‹œ
                            if result['rank'] <= 10:
                                st.success(f"ğŸ¥‡ TOP 10 ìˆœìœ„!")
                            elif result['rank'] <= 50:
                                st.info(f"ğŸ¥ˆ TOP 50 ìˆœìœ„!")
                            elif result['rank'] <= 100:
                                st.warning(f"ğŸ¥‰ TOP 100 ìˆœìœ„!")
                            else:
                                st.error(f"ğŸ“‰ 100ìœ„ ì´í•˜")
                    else:
                        st.markdown(f"**âŒ ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ**")
                        st.markdown("í•´ë‹¹ í‚¤ì›Œë“œì—ì„œ ì§€ì •ëœ íŒë§¤ì²˜ì˜ ìƒí’ˆì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        else:
            st.info("ğŸ‘† ìœ„ì—ì„œ ê²€ìƒ‰ì–´ì™€ íŒë§¤ì²˜ëª…ì„ ì…ë ¥í•œ í›„ 'ìˆœìœ„ í™•ì¸' ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.")
    
    with tab2:
        # ì—°ê´€í‚¤ì›Œë“œ ì¡°íšŒ
        related_search_button = st.button("ğŸ”— ì—°ê´€í‚¤ì›Œë“œ ì¡°íšŒ", type="primary", key="related_keywords")
        
        if related_search_button:
            keywords = [k.strip() for k in keywords_text.split(",") if k.strip()]
            
            if not keywords:
                st.error("âŒ ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            else:
                st.header("ğŸ”— ì—°ê´€í‚¤ì›Œë“œ ì¡°íšŒ ê²°ê³¼")
                
                for keyword in keywords:
                    with st.expander(f"ğŸ” {keyword}ì˜ ì—°ê´€í‚¤ì›Œë“œ ë¶„ì„", expanded=True):
                        with st.spinner(f"{keyword} ì—°ê´€í‚¤ì›Œë“œ ì¡°íšŒ ì¤‘..."):
                            related_keywords = get_related_keywords(keyword)
                        
                        if related_keywords:
                            st.success(f"âœ… {len(related_keywords)}ê°œì˜ ì—°ê´€í‚¤ì›Œë“œë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤.")
                            
                            # ë¶„ì„ ê²°ê³¼ë¥¼ íƒ­ìœ¼ë¡œ êµ¬ë¶„
                            analysis_tab1, analysis_tab2, analysis_tab3 = st.tabs(["ğŸ“‹ í‚¤ì›Œë“œ ëª©ë¡", "ğŸ“Š ë¶„ì„ ì°¨íŠ¸", "ğŸ’¾ ë‚´ë³´ë‚´ê¸°"])
                            
                            with analysis_tab1:
                                # 2ì—´ ë ˆì´ì•„ì›ƒ: ì™¼ìª½(ì—°ê´€í‚¤ì›Œë“œ), ì˜¤ë¥¸ìª½(ê²½ìŸì •ë„)
                                col_left, col_right = st.columns([3, 2])
                                
                                with col_left:
                                    st.subheader("ğŸ“ ì—°ê´€í‚¤ì›Œë“œ ëª©ë¡")
                                    # 3ì—´ë¡œ ì—°ê´€í‚¤ì›Œë“œ í‘œì‹œ
                                    cols = st.columns(3)
                                    for i, related_kw in enumerate(related_keywords):
                                        with cols[i % 3]:
                                            st.write(f"â€¢ {related_kw}")
                                
                                with col_right:
                                    st.subheader("âš”ï¸ ê²½ìŸì •ë„ ë¶„ì„")
                                    st.write("**PCí†µí•©ê²€ìƒ‰ì˜ì—­ ê¸°ì¤€**")
                                    
                                    # ì›ë³¸ í‚¤ì›Œë“œ ê²½ìŸì •ë„
                                    with st.spinner(f"{keyword} ê²½ìŸì •ë„ ë¶„ì„ ì¤‘..."):
                                        competition, total_results, icon = get_keyword_competition_level(keyword)
                                    
                                    st.markdown(f"""
                                    **ğŸ¯ ë©”ì¸ í‚¤ì›Œë“œ: {keyword}**
                                    - {icon} **ê²½ìŸì •ë„**: {competition}
                                    - ğŸ“Š **ê²€ìƒ‰ê²°ê³¼**: {total_results:,}ê°œ
                                    """)
                                    
                                    st.markdown("---")
                                    
                                    # ì—°ê´€í‚¤ì›Œë“œ ì¤‘ ìƒìœ„ 5ê°œì˜ ê²½ìŸì •ë„ ë¶„ì„
                                    st.write("**ğŸ” ì—°ê´€í‚¤ì›Œë“œ ê²½ìŸì •ë„ (ìƒìœ„ 5ê°œ)**")
                                    
                                    for i, related_kw in enumerate(related_keywords[:5]):
                                        with st.spinner(f"{related_kw} ë¶„ì„ ì¤‘..."):
                                            comp, total, icon = get_keyword_competition_level(related_kw)
                                        
                                        # ê²½ìŸì •ë„ì— ë”°ë¥¸ ìƒ‰ìƒ ì„¤ì •
                                        if comp == "ë†’ìŒ":
                                            color = "red"
                                        elif comp == "ì¤‘ê°„":
                                            color = "orange"
                                        else:
                                            color = "green"
                                        
                                        st.markdown(f"""
                                        <div style="padding: 5px; margin: 2px 0; border-left: 3px solid {color};">
                                            <strong>{related_kw}</strong><br>
                                            {icon} {comp} ({total:,}ê°œ)
                                        </div>
                                        """, unsafe_allow_html=True)
                                    
                                    # ê²½ìŸì •ë„ ë²”ë¡€
                                    st.markdown("---")
                                    st.markdown("""
                                    **ğŸ“‹ ê²½ìŸì •ë„ ê¸°ì¤€**
                                    - ğŸ”´ **ë†’ìŒ**: 100ë§Œê°œ ì´ìƒ
                                    - ğŸŸ¡ **ì¤‘ê°„**: 10ë§Œ~100ë§Œê°œ
                                    - ğŸŸ¢ **ë‚®ìŒ**: 10ë§Œê°œ ë¯¸ë§Œ
                                    """)
                            
                            with analysis_tab2:
                                # í‚¤ì›Œë“œ ë¶„ì„ ì°¨íŠ¸
                                st.subheader("ğŸ“Š í‚¤ì›Œë“œ ë¶„ì„")
                                
                                # í‚¤ì›Œë“œ ìœ í˜•ë³„ ë¶„ë¥˜
                                keyword_analysis = analyze_keyword_types(related_keywords, keyword)
                                
                                if keyword_analysis:
                                    col1, col2 = st.columns(2)
                                    
                                    with col1:
                                        st.markdown("**í‚¤ì›Œë“œ ìœ í˜•ë³„ ë¶„í¬**")
                                        for kw_type, count in keyword_analysis.items():
                                            percentage = (count / len(related_keywords)) * 100
                                            st.write(f"â€¢ {kw_type}: {count}ê°œ ({percentage:.1f}%)")
                                    
                                    with col2:
                                        # í‚¤ì›Œë“œ í†µê³„
                                        insights = get_keyword_insights(related_keywords, keyword)
                                        st.markdown("**í‚¤ì›Œë“œ í†µê³„**")
                                        st.write(f"â€¢ í‰ê·  ê¸¸ì´: {insights['avg_length']:.1f}ì")
                                        st.write(f"â€¢ ìµœë‹¨/ìµœì¥: {insights['min_length']}/{insights['max_length']}ì")
                                        st.write(f"â€¢ êµ¬ë§¤ ì˜ë„: {insights['purchase_ratio']:.1f}%")
                                        st.write(f"â€¢ ê³ ìœ  ë‹¨ì–´: {insights['unique_words']}ê°œ")
                                
                                # í‚¤ì›Œë“œ ì›Œë“œí´ë¼ìš°ë“œ (í…ìŠ¤íŠ¸ ê¸°ë°˜)
                                st.markdown("**ğŸ”¤ ì£¼ìš” í‚¤ì›Œë“œ êµ¬ì„± ìš”ì†Œ**")
                                all_words = []
                                for kw in related_keywords:
                                    all_words.extend(kw.split())
                                
                                from collections import Counter
                                word_freq = Counter(all_words)
                                # ê¸°ì¤€ í‚¤ì›Œë“œ ì œì™¸
                                word_freq.pop(keyword, None)
                                
                                # ìƒìœ„ 10ê°œ ë‹¨ì–´ í‘œì‹œ
                                top_words = word_freq.most_common(10)
                                if top_words:
                                    word_text = " | ".join([f"{word}({count})" for word, count in top_words])
                                    st.text(word_text)
                            
                            with analysis_tab3:
                                # ë°ì´í„° ë‚´ë³´ë‚´ê¸°
                                st.subheader("ğŸ’¾ ë°ì´í„° ë‚´ë³´ë‚´ê¸°")
                                
                                # CSV ë‹¤ìš´ë¡œë“œ
                                import pandas as pd  # ëª…ì‹œì  import ì¶”ê°€
                                from datetime import datetime
                                
                                # ìƒì„¸ ë°ì´í„°í”„ë ˆì„ ìƒì„±
                                detailed_data = []
                                for i, kw in enumerate(related_keywords, 1):
                                    kw_type = "ê¸°íƒ€"
                                    if any(intent in kw for intent in ['ì¶”ì²œ', 'ìˆœìœ„', 'êµ¬ë§¤', 'ë¦¬ë·°', 'í›„ê¸°', 'ë¹„êµ']):
                                        kw_type = "êµ¬ë§¤ì˜ë„"
                                    elif any(brand in kw for brand in ['ë¸Œëœë“œ', 'ì •í’ˆ', 'í”„ë¦¬ë¯¸ì—„', 'ê³ ê¸‰', 'ë² ìŠ¤íŠ¸', 'ì¸ê¸°']):
                                        kw_type = "ë¸Œëœë“œ/í’ˆì§ˆ"
                                    elif any(feature in kw for feature in ['ë¬´ì„ ', 'ë¸”ë£¨íˆ¬ìŠ¤', 'USB', 'ê²Œì´ë°', 'ì‚¬ë¬´ìš©', 'ê°€ì •ìš©']):
                                        kw_type = "ê¸°ëŠ¥/íŠ¹ì„±"
                                    elif any(price in kw for price in ['ê°€ê²©', 'í• ì¸', 'íŠ¹ê°€', 'ì„¸ì¼', 'ì €ë ´', 'ê°€ì„±ë¹„']):
                                        kw_type = "ê°€ê²©/í• ì¸"
                                    
                                    detailed_data.append({
                                        'ìˆœìœ„': i,
                                        'ì—°ê´€í‚¤ì›Œë“œ': kw,
                                        'í‚¤ì›Œë“œìœ í˜•': kw_type,
                                        'í‚¤ì›Œë“œê¸¸ì´': len(kw),
                                        'ê¸°ì¤€í‚¤ì›Œë“œ': keyword,
                                        'ì¡°íšŒì¼ì‹œ': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                                    })
                                
                                df = pd.DataFrame(detailed_data)
                                csv = df.to_csv(index=False, encoding='utf-8-sig')
                                
                                st.download_button(
                                    label="ğŸ“¥ ìƒì„¸ ë¶„ì„ CSV ë‹¤ìš´ë¡œë“œ",
                                    data=csv,
                                    file_name=f"ì—°ê´€í‚¤ì›Œë“œ_ë¶„ì„_{keyword}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                                    mime="text/csv"
                                )
                                
                                # ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°
                                st.markdown("**ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°:**")
                                st.dataframe(df, width="stretch")
                                
                                # í‚¤ì›Œë“œ ë³µì‚¬ìš© í…ìŠ¤íŠ¸
                                st.markdown("**í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸ (ë³µì‚¬ìš©):**")
                                keywords_text = '\n'.join([f"{i+1}. {kw}" for i, kw in enumerate(related_keywords)])
                                st.text_area("í‚¤ì›Œë“œ ëª©ë¡", keywords_text, height=150, key=f"copy_{keyword}")
                                
                                # ìš”ì•½ í†µê³„
                                st.markdown("**ğŸ“ˆ ìš”ì•½ í†µê³„:**")
                                summary_col1, summary_col2, summary_col3 = st.columns(3)
                                
                                with summary_col1:
                                    st.metric("ì´ í‚¤ì›Œë“œ ìˆ˜", len(related_keywords))
                                
                                with summary_col2:
                                    purchase_count = sum(1 for kw in related_keywords 
                                                       if any(intent in kw for intent in ['ì¶”ì²œ', 'ê°€ê²©', 'í• ì¸', 'êµ¬ë§¤', 'ìˆœìœ„']))
                                    st.metric("êµ¬ë§¤ ì˜ë„ í‚¤ì›Œë“œ", purchase_count)
                                
                                with summary_col3:
                                    avg_length = sum(len(kw) for kw in related_keywords) / len(related_keywords)
                                    st.metric("í‰ê·  í‚¤ì›Œë“œ ê¸¸ì´", f"{avg_length:.1f}ì")
                        else:
                            st.warning("âŒ ì—°ê´€í‚¤ì›Œë“œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        else:
            st.info("ğŸ‘† ìœ„ì—ì„œ ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•œ í›„ 'ì—°ê´€í‚¤ì›Œë“œ ì¡°íšŒ' ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.")
    
    with tab3:
        # ì‡¼í•‘ ìˆœìœ„ ë¦¬ìŠ¤íŠ¸
        ranking_search_button = st.button("ğŸ“Š ì‡¼í•‘ ìˆœìœ„ ë¦¬ìŠ¤íŠ¸", type="primary", key="shopping_rank")
        
        if ranking_search_button:
            keywords = [k.strip() for k in keywords_text.split(",") if k.strip()]
            
            if not keywords:
                st.error("âŒ ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            else:
                st.header("ğŸ“Š ì‡¼í•‘ ìˆœìœ„ ë¦¬ìŠ¤íŠ¸")
                
                for keyword in keywords:
                    with st.expander(f"ğŸ” {keyword} ìˆœìœ„ ë¦¬ìŠ¤íŠ¸", expanded=True):
                        with st.spinner(f"{keyword} ìˆœìœ„ ì¡°íšŒ ì¤‘..."):
                            products = get_shopping_rank_list(keyword)
                        
                        if products:
                            st.success(f"âœ… {len(products)}ê°œì˜ ìƒí’ˆì„ ì°¾ì•˜ìŠµë‹ˆë‹¤.")
                            
                            # ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ í‘œì‹œ
                            import pandas as pd  # ëª…ì‹œì  import ì¶”ê°€
                            df = pd.DataFrame(products)
                            df['ê°€ê²©'] = df['price'].apply(lambda x: f"{x:,}ì›" if x > 0 else "ê°€ê²© ë¯¸í‘œì‹œ")
                            
                            # í‘œì‹œí•  ì»¬ëŸ¼ ì„ íƒ
                            display_df = df[['rank', 'title', 'ê°€ê²©', 'mallName']].copy()
                            display_df.columns = ['ìˆœìœ„', 'ìƒí’ˆëª…', 'ê°€ê²©', 'íŒë§¤ì²˜']
                            
                            st.dataframe(
                                display_df,
                                width="stretch",
                                hide_index=True
                            )
                        else:
                            st.warning("âŒ ìˆœìœ„ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        else:
            st.info("ğŸ‘† ìœ„ì—ì„œ ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•œ í›„ 'ì‡¼í•‘ ìˆœìœ„ ë¦¬ìŠ¤íŠ¸' ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.")
    
    with tab4:
        # ì›”ê°„ ê²€ìƒ‰ìˆ˜
        volume_search_button = st.button("ğŸ“ˆ ì›”ê°„ ê²€ìƒ‰ìˆ˜ ì¡°íšŒ", type="primary", key="search_volume")
        
        if volume_search_button:
            keywords = [k.strip() for k in keywords_text.split(",") if k.strip()]
            
            if not keywords:
                st.error("âŒ ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            else:
                st.header("ğŸ“ˆ ì›”ê°„ ê²€ìƒ‰ìˆ˜ ì¡°íšŒ ê²°ê³¼")
                
                for keyword in keywords:
                    with st.expander(f"ğŸ” {keyword} ê²€ìƒ‰ëŸ‰", expanded=True):
                        with st.spinner(f"{keyword} ê²€ìƒ‰ëŸ‰ ì¡°íšŒ ì¤‘..."):
                            volume_data = get_keyword_search_volume(keyword)
                        
                        if volume_data:
                            col1, col2, col3 = st.columns(3)
                            
                            with col1:
                                st.metric(
                                    label="ğŸ“± ëª¨ë°”ì¼ ê²€ìƒ‰ëŸ‰",
                                    value=f"{volume_data['mobile_volume']:,}",
                                    delta=f"{volume_data['mobile_ratio']:.1f}%"
                                )
                            
                            with col2:
                                st.metric(
                                    label="ğŸ’» PC ê²€ìƒ‰ëŸ‰", 
                                    value=f"{volume_data['pc_volume']:,}",
                                    delta=f"{volume_data['pc_ratio']:.1f}%"
                                )
                            
                            with col3:
                                st.metric(
                                    label="ğŸ“Š ì´ ê²€ìƒ‰ëŸ‰",
                                    value=f"{volume_data['total_volume']:,}"
                                )
                            
                            # í˜„ì¬ ì›” ë¹„ìœ¨ ì°¨íŠ¸
                            st.subheader("ğŸ“Š ë””ë°”ì´ìŠ¤ë³„ ê²€ìƒ‰ ë¹„ìœ¨")
                            import pandas as pd  # ëª…ì‹œì  import ì¶”ê°€
                            chart_data = pd.DataFrame({
                                'êµ¬ë¶„': ['ëª¨ë°”ì¼', 'PC'],
                                'ê²€ìƒ‰ëŸ‰': [volume_data['mobile_volume'], volume_data['pc_volume']]
                            })
                            st.bar_chart(chart_data.set_index('êµ¬ë¶„'))
                            
                            # íŠ¸ë Œë“œ ì°¨íŠ¸ ì¶”ê°€
                            if 'pc_trend_data' in volume_data and 'mobile_trend_data' in volume_data:
                                st.subheader("ğŸ“ˆ ê²€ìƒ‰ëŸ‰ íŠ¸ë Œë“œ (ìµœê·¼ 1ë…„)")
                                
                                # íŠ¸ë Œë“œ ë°ì´í„° ì¤€ë¹„
                                trend_data = []
                                pc_trends = volume_data['pc_trend_data']
                                mobile_trends = volume_data['mobile_trend_data']
                                
                                for i in range(min(len(pc_trends), len(mobile_trends))):
                                    trend_data.append({
                                        'ë‚ ì§œ': pc_trends[i]['period'],
                                        'PC': pc_trends[i]['ratio'],
                                        'ëª¨ë°”ì¼': mobile_trends[i]['ratio']
                                    })
                                
                                if trend_data:
                                    import pandas as pd  # ëª…ì‹œì  import ì¶”ê°€
                                    trend_df = pd.DataFrame(trend_data)
                                    trend_df['ë‚ ì§œ'] = pd.to_datetime(trend_df['ë‚ ì§œ'])
                                    trend_df = trend_df.set_index('ë‚ ì§œ')
                                    
                                    st.line_chart(trend_df)
                                    
                                    # íŠ¸ë Œë“œ ë¶„ì„
                                    if len(trend_data) >= 2:
                                        recent_total = pc_trends[-1]['ratio'] + mobile_trends[-1]['ratio']
                                        previous_total = pc_trends[-2]['ratio'] + mobile_trends[-2]['ratio']
                                        change = recent_total - previous_total
                                        
                                        if change > 0:
                                            st.success(f"ğŸ“ˆ ìµœê·¼ ê²€ìƒ‰ëŸ‰ì´ {abs(change):.1f}% ì¦ê°€í–ˆìŠµë‹ˆë‹¤.")
                                        elif change < 0:
                                            st.warning(f"ğŸ“‰ ìµœê·¼ ê²€ìƒ‰ëŸ‰ì´ {abs(change):.1f}% ê°ì†Œí–ˆìŠµë‹ˆë‹¤.")
                                        else:
                                            st.info("ï¿½ ìµœê·¼ ê²€ìƒ‰ëŸ‰ì´ ìœ ì§€ë˜ê³  ìˆìŠµë‹ˆë‹¤.")
                            
                            st.info("ğŸ’¡ ìœ„ ë°ì´í„°ëŠ” ë„¤ì´ë²„ DataLab APIì—ì„œ ì œê³µí•˜ëŠ” ì‹¤ì œ ê²€ìƒ‰ëŸ‰ ë°ì´í„°ì…ë‹ˆë‹¤.")
                        else:
                            st.warning("âŒ ê²€ìƒ‰ëŸ‰ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        else:
            st.info("ğŸ‘† ìœ„ì—ì„œ ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•œ í›„ 'ì›”ê°„ ê²€ìƒ‰ìˆ˜ ì¡°íšŒ' ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.")
    
    # í‘¸í„°
    st.markdown("---")
    st.markdown(
        "<div style='text-align: center; color: gray; font-size: 12px;'>"
        "â“’ 2025 chaechaeLab. ë¬´ë‹¨ ë³µì œ ë° ë°°í¬ ê¸ˆì§€. All rights reserved."
        "</div>", 
        unsafe_allow_html=True
    )

if __name__ == "__main__":
    main()